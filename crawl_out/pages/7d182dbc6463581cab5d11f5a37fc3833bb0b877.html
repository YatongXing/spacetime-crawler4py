<!-- URL: http://seal.ics.uci.edu/projects/reca11/index.html -->
<!DOCTYPE html>
<html lang="en">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-83301040-1', 'auto');
  ga('send', 'pageview');

</script>
<head>
<title>SEAL - Reca11</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta http-equiv="Reply-to" content="malek at uci dot edu">
<meta http-equiv="Owner" content="Sam Malek">
<meta name="Author" content="Sam Malek">
<meta name="Generator" content="Emacs">
<link rev="MADE" href="mailto:malek at uci dot edu">
<link href="../../seal.css" rel="stylesheet" type="text/css">
</head>

<body>
<div class="wrapper">
    
<!-- *************** Beginning of content ****************** -->

<h2>Automated Generation of Accessibility Test Reports from Recorded User Transcripts</h2>

<p>
  Testing for accessibility is a significant step when developing software, as it ensures that all users, including those with disabilities, can effectively engage with web and mobile applications. While automated tools exist to detect accessibility issues in software, none are as comprehensive and effective as the process of user testing, where testers with various disabilities evaluate the application for accessibility and usability issues. However, user testing is not popular with software developers as it requires conducting lengthy interviews with users and later parsing through large recordings to derive the issues to fix. In this paper, we explore how large language models (LLMs) like GPT 4.0, which have shown promising results in context comprehension and semantic text generation, can mitigate this issue and streamline the user testing process. Our solution, called Reca11, takes in informal transcripts of test recordings and extracts the accessibility and usability issues mentioned by the tester. Our systematic prompt engineering determines the optimal configuration of input, instruction, context and demonstrations for best results. We evaluate Reca11's effectiveness on 36 user testing sessions across three applications. Based on the findings, we investigate the strengths and weaknesses of using LLMs in this space.
</p>

<img style="margin:10" ALT="A diagram depicting the design for Reca11. Reca11 takes in input from the user testing process: transcript, guidelines, tasks and technical information. It uses GPT 4 to output a test report, which is a list of accessibility issues." height="250" src=./rec.png><br>


<h3>Publications</h3>

More details about can be found in our publication below:
<br>
<ul class="paperlist">
    <li><b>Automated Generation of Accessibility Test Reports from Recorded User Transcripts</b><br> 
    Syed Fatiul Huq, Mahan Tafreshipour, Kate Kalcevich and Sam Malek<br>
    <i>47th IEEE/ACM International Conference on Software Engineering (ICSE 2025), Ottawa, Canada, April 2025.</i>
    <br>[<a href="./a11ydev.pdf">PDF</a>]
    </li> 
</ul>

<!-- ***************** End of content ****************** -->
<br><br>
<div style="float:left">
            <a href="http://www.ics.uci.edu/~seal/"><img ALT="[seal's logo]" height="200" src=../../seal.png></a>
</div>
<div style="float:right">
            <a href="http://www.ics.uci.edu"><img ALT="[uci's logo]" style="padding-top: 40px" height="100" src=../../uci.jpg></a>
</div>
</div>
</body>