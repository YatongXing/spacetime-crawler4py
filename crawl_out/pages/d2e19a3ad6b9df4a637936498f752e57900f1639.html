<!-- URL: https://www.ics.uci.edu/~dechter/publications/r269.html -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Dr. Rina Dechter @ UCI</title>
  <link rel="Stylesheet" href="/%7Edechter/basic.css">
</head>
<body alink="#00aaaa" bgcolor="#ffffff" link="#008080" vlink="#008080">
<!-- Begin Header -->[an error occurred while processing this directive]<!-- End Header --><!-- Begin Body --><br><br><center>
<table width=90%>
<tr>
<td class=title>Publications & Technical Reports</td>
<tr>
  <td colspan=2><img width="100%" height="2"  src="/~dechter/images/black-fill.gif"></td>
</tr>
</tr>
</table>
</center> 
<center>
<table border="0" cellpadding="0" cellspacing="0" width="80%">
  <tbody>
    <tr valign="top">
      <td><b>R269</b></td>
<br>
      <br>
      </td>
    </tr>
    <tr>
      <td colspan="2">
      <div class="title"><span style="font-weight: bold;">
      NeuroBE: Escalating NN Approximations to Bucket Elimination
      </span></div>
      <span style="font-weight: bold;">
      Sakshi Agarwal, Kalev Kask, Alex Ihler, and Rina Dechter.
      </span><br>
      <tt></tt></td>
    </tr>
  </tbody>
</table>
<table border="0" cellpadding="0" cellspacing="0" width="80%">
  <tbody>
    <tr>
      <td><br>
      <div class="abstract"><b>Abstract</b><br>
    	  <div style="text-align: justify;">
			A major limiting factor in graphical model inference is
the complexity of computing the partition function. Exact
message-passing algorithms such as Bucket Elimination (BE)
require exponentially high levels of memory to compute the
partition function, therefore approximations are necessary. In
this paper, we build upon a recently introduced methodology
called Deep Bucket Elimination (DBE) that uses classical
Neural Networks (NNs) to approximate messages generated
by BE when buckets have large memory requirements.
The main feature of our new scheme called NeuroBE is
that it customizes the architecture and learning of the NNs to
the message size and its distribution. We also explore a new
loss function for training taking into account the estimated
message cost distribution. Our experiments demonstrate that
these enhancements provide significant improvements over
DBE in both time and accuracy. We also study the impact
of the messages local errors on the global accuracy of the estimate
of the partition function.
	 </div>
      <br>
      <a target="blank" href="r269.pdf">
      <b>[pdf]</b></a>
      </td>
    </tr>
  </tbody>
</table>
</center>
<br>
<!-- End Body-->
<!--- Begin Footer --><div id="footer"><centeR>
<A HREF="http://www.ics.uci.edu">School of Information and Computer Science</A>
<A HREF="http://www.uci.edu">University of California, Irvine, CA 92697-3435</a>
<A HREF="http://www.ics.uci.edu/~dechter">Dr. Rina Dechter</A>

<A HREF="mailto:dechter_at_ics.uci.edu">dechter at ics.uci.edu</A>

</center></div><!--- End Footer -->
</body>
</html>
